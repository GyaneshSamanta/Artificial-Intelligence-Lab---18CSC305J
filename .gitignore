numofbanana = int(input("Enter the number of bananas: "))
totdistance = int(input("Enter the distance you wanna cover: "))
maxload = int(input("Enter max load capacity of your camel: "))
start = numofbanana
lose = 0
for i in range(totdistance):
if start==0:
break
while start>0:
start = start-maxload
if start==1:
lose-=1
lose+=2
lose-=1
start=numofbanana-lose
print(start)

##Developing agent programs for real world problems(Graph Colouring problem)

class Graph:
def init (self, edges, n):
self.adjList = [[] for _ in range(n)]
for (src, dest) in edges:
self.adjList[src].append(dest)
self.adjList[dest].append(src)
def colorGraph(graph, n):
result = {}
for u in range(n):
assigned = set([result.get(i) for i in graph.adjList[u] if i in result])
color = 1
for c in assigned:
if color != c:
break
color = color + 1
result[u] = color
for v in range(n):
print(f'Color assigned to vertex {v} is {colors[result[v]]}')
if name == ' main ':
colors = ['', 'BLUE', 'GREEN', 'RED', 'YELLOW', 'ORANGE', 'PINK',
'BLACK', 'BROWN', 'WHITE', 'PURPLE', 'VOILET']
edges = [(0, 1), (0, 4), (0, 5), (4, 5), (1, 4), (1, 3), (2, 3), (2, 4)]
n = 6
graph = Graph(edges, n)
colorGraph(graph, n)


##constraint satisfaction problem

import itertools
def get_value(word, substitution):
s = 0
factor = 1
for letter in reversed(word):
s += factor * substitution[letter]
factor *= 10
return s
def solve2(equation):
left, right = equation.lower().replace(' ', '').split('=')
left = left.split('+')
letters = set(right)
for word in left:
for letter in word:
letters.add(letter)
letters = list(letters)
digits = range(10)
for perm in itertools.permutations(digits, len(letters)):
sol = dict(zip(letters, perm))
if sum(get_value(word, sol) for word in left) == get_value(right, sol):
print(' + '.join(str(get_value(word, sol)) for word in left) + " = {} (mapping:
{})".format(get_value(right, sol), sol))
print('EAT + THAT = APPLE ')
solve2('POINT + ZERO = ENERGY ')

##implementation of DFS and BFS
##(BFS)
graph = {
'5' : ['3','7'],
'3' : ['2', '4'],
'7' : ['8'],
'2' : [],
'4' : ['8'],
'8' : []
}
visited = []
queue = []
def bfs(visited, graph, node):
visited.append(node)
queue.append(node)
while queue:
m = queue.pop(0)
print (m, end = " ")
for neighbour in graph[m]:
if neighbour not in visited:
visited.append(neighbour)
queue.append(neighbour)
# Driver Code
print("Following is the Breadth-First Search")
bfs(visited, graph, '5')

##DFS

graph={
'A':['B','C'],
'B':['D'],
'C':['F'],
'D':['E','F'],
'E':[],
'F':['A']
}
visited=set()
def dfs(visited,graph,node):
if node not in visited:
print(node)
visited.add(node)
for neighbour in graph[node]:
dfs(visited,graph,neighbour)
dfs(visited,graph,'A')

##Implementation of best first search

from queue import PriorityQueue
v = 14
graph = [[] for i in range(v)]
def best_first_search(source, target, n):
visited = [0] * n
visited[0] = True
pq = PriorityQueue()
pq.put((0, source))
while pq.empty() == False:
u = pq.get()[1]
print(u, end=" ")
if u == target:
break
for v, c in graph[u]:
if visited[v] == False:
visited[v] = True
pq.put((c, v))
print()
def addedge(x, y, cost):
graph[x].append((y, cost))
graph[y].append((x, cost))
addedge(0, 1, 3)
addedge(0, 2, 6)
addedge(0, 3, 5)
addedge(1, 4, 9)
addedge(1, 5, 8)
addedge(2, 6, 12)
addedge(2, 7, 14)
addedge(3, 8, 7)
addedge(8, 9, 5)
addedge(8, 10, 6)
addedge(9, 11, 1)
addedge(9, 12, 10)
addedge(9, 13, 2)
source = 0
target = 9
best_first_search(source, target, v)

##Implementation of A* Algorithm

def aStarAlgo(start_node, stop_node):
open_set = set(start_node)
closed_set = set()
g = {}
parents = {}
g[start_node] = 0
parents[start_node] = start_node
while len(open_set) > 0:
n = None
for v in open_set:
if n == None or g[v] + heuristic(v) < g[n] + heuristic(n):
n = v
if n == stop_node or Graph_nodes[n] == None:
pass
else:
for (m, weight) in get_neighbors(n):
if m not in open_set and m not in closed_set:
open_set.add(m)
parents[m] = n
g[m] = g[n] + weight
else:
if g[m] > g[n] + weight:
g[m] = g[n] + weight
parents[m] = n
if m in closed_set:
closed_set.remove(m)
open_set.add(m)
if n == None:
print('Path does not exist!')
return None
if n == stop_node:
path = []
while parents[n] != n:
path.append(n)
n = parents[n]
path.append(start_node)
path.reverse()
print('Path found: {}'.format(path))
return path
open_set.remove(n)
closed_set.add(n)
print('Path does not exist!')
return None
def get_neighbors(v):
if v in Graph_nodes:
return Graph_nodes[v]
else:
return None
def heuristic(n):
H_dist = {
'A': 11,
'B': 6,
'C': 99,
'D': 1,
'E': 7,
'G': 0,
}
return H_dist[n]
Graph_nodes = {
'A': [('B', 2), ('E', 3)],
'B': [('C', 1),('G', 9)],
'C': None,
'E': [('D', 6)],
'D': [('G', 1)],
}
aStarAlgo('A', 'G')


##implementation of minmax algo for an application

import random
class TicTacToe(object):
winning_combos = (
[0, 1, 2], [3, 4, 5], [6, 7, 8],
[0, 3, 6], [1, 4, 7], [2, 5, 8],
[0, 4, 8], [2, 4, 6]
)
winners = ('X-win', 'Draw', 'O-win')
def init (self, board=[]):
if len(board) == 0:
self.board = [0 for i in range(9)]
else:
self.board = board
def print_board(self):
for i in range(3):
print(
"| " + str(self.board[i * 3]) +
" | " + str(self.board[i * 3 + 1]) +
" | " + str(self.board[i * 3 + 2]) + " |"
)
def check_game_over(self):
if 0 not in [element for element in self.board]:
return True
if self.winner() != 0:
return True
return False
def available_moves(self):
return [index for index, element in enumerate(self.board) if element is 0]
def available_combos(self, player):
return self.available_moves() + self.get_acquired_places(player)
def X_won(self):
return self.winner() == 'X'
def O_won(self):
return self.winner() == 'O'
def is_tie(self):
return self.winner() == 0 and self.check_game_over()
def winner(self):
for player in ('X', 'O'):
positions = self.get_acquired_places(player)
for combo in self.winning_combos:
win = True
for pos in combo:
if pos not in positions:
win = False
if win:
return player
return 0
def get_acquired_places(self, player):
return [index for index, element in enumerate(self.board) if element == player]
def make_move(self, position, player):
self.board[position] = player
def minimax(self, node, player):
if node.check_game_over():
if node.X_won():
return -1
elif node.is_tie():
return 0
elif node.O_won():
return 1
best = 0
for move in node.available_moves():
node.make_move(move, player)
val = self.minimax(node, get_enemy(player))
node.make_move(move, 0)
if player == 'O':
if val > best:
best = val
else:
if val < best:
best = val
return best
def determine(board, player):
'''
Driver function to apply minimax algorithm
'''
a = 0
choices = []
if len(board.available_moves()) == 9:
return 4
for move in board.available_moves():
board.make_move(move, player)
val = board.minimax(board, get_enemy(player))
board.make_move(move, 0)
if val > a:
a = val
choices = [move]
elif val == a:
choices.append(move)
try:
return random.choice(choices)
except IndexError:
return random.choice(board.available_moves())
def get_enemy(player):
if player == 'X':
return 'O'
return 'X'
if name == " main ":
board = TicTacToe()
print('Board positions are like this: ')
for i in range(3):
print(
"| " + str(i * 3 + 1) +
" | " + str(i * 3 + 2) +
" | " + str(i * 3 + 3) + " |"
)
print('Type in the position number you to make a move on..')
while not board.check_game_over():
player = 'X'
player_move = int(input("Your Move: ")) - 1
if player_move not in board.available_moves():
print('Please check the input!')
continue
board.make_move(player_move, player)
board.print_board()
print()
if board.check_game_over():
break
print('Computer is playing.. ')
player = get_enemy(player)
computer_move = determine(board, player)
board.make_move(computer_move, player)
board.print_board()
if board.winner() != 0:
if board.winner() == 'X':
print ("Congratulations you win!")
else:
print('Computer Wins!')
else:
print("Game tied!")

##Unification algorithm

def get_index_comma(string):
    index_list = list()
    par_count = 0

    for i in range(len(string)):
        if string[i] == ',' and par_count == 0:
            index_list.append(i)
        elif string[i] == '(':
            par_count += 1
        elif string[i] == ')':
            par_count -= 1

    return index_list


def is_variable(expr):
    for i in expr:
        if i == '(' or i == ')':
            return False

    return True


def process_expression(expr):
    expr = expr.replace(' ', '')
    index = None
    for i in range(len(expr)):
        if expr[i] == '(':
            index = i
            break
    predicate_symbol = expr[:index]
    expr = expr.replace(predicate_symbol, '')
    expr = expr[1:len(expr) - 1]
    arg_list = list()
    indices = get_index_comma(expr)

    if len(indices) == 0:
        arg_list.append(expr)
    else:
        arg_list.append(expr[:indices[0]])
        for i, j in zip(indices, indices[1:]):
            arg_list.append(expr[i + 1:j])
        arg_list.append(expr[indices[len(indices) - 1] + 1:])

    return predicate_symbol, arg_list


def get_arg_list(expr):
    _, arg_list = process_expression(expr)

    flag = True
    while flag:
        flag = False

        for i in arg_list:
            if not is_variable(i):
                flag = True
                _, tmp = process_expression(i)
                for j in tmp:
                    if j not in arg_list:
                        arg_list.append(j)
                arg_list.remove(i)

    return arg_list


def check_occurs(var, expr):
    arg_list = get_arg_list(expr)
    if var in arg_list:
        return True

    return False


def unify(expr1, expr2):

    if is_variable(expr1) and is_variable(expr2):
        if expr1 == expr2:
            return 'Null'
        else:
            return False
    elif is_variable(expr1) and not is_variable(expr2):
        if check_occurs(expr1, expr2):
            return False
        else:
            tmp = str(expr2) + '/' + str(expr1)
            return tmp
    elif not is_variable(expr1) and is_variable(expr2):
        if check_occurs(expr2, expr1):
            return False
        else:
            tmp = str(expr1) + '/' + str(expr2)
            return tmp
    else:
        predicate_symbol_1, arg_list_1 = process_expression(expr1)
        predicate_symbol_2, arg_list_2 = process_expression(expr2)

        # Step 2
        if predicate_symbol_1 != predicate_symbol_2:
            return False
        # Step 3
        elif len(arg_list_1) != len(arg_list_2):
            return False
        else:
            # Step 4: Create substitution list
            sub_list = list()

            # Step 5:
            for i in range(len(arg_list_1)):
                tmp = unify(arg_list_1[i], arg_list_2[i])

                if not tmp:
                    return False
                elif tmp == 'Null':
                    pass
                else:
                    if type(tmp) == list:
                        for j in tmp:
                            sub_list.append(j)
                    else:
                        sub_list.append(tmp)

            # Step 6
            return sub_list


if _name_ == '_main_':
   
    f1 = 'Q(a, g(x, a), f(y))'
    f2 = 'Q(a, g(f(b), a), x)'
    # f1 = input('f1 : ')
    # f2 = input('f2 : ')

    result = unify(f1, f2)
    if not result:
        print('The process of Unification failed!')
    else:
        print('The process of Unification successful!')
        print(result)

##Resolution
import copy
import time


class Parameter:
    variable_count = 1

    def _init_(self, name=None):
        if name:
            self.type = "Constant"
            self.name = name
        else:
            self.type = "Variable"
            self.name = "v" + str(Parameter.variable_count)
            Parameter.variable_count += 1

    def isConstant(self):
        return self.type == "Constant"

    def unify(self, type_, name):
        self.type = type_
        self.name = name

    def _eq_(self, other):
        return self.name == other.name

    def _str_(self):
        return self.name


class Predicate:
    def _init_(self, name, params):
        self.name = name
        self.params = params

    def _eq_(self, other):
        return self.name == other.name and all(a == b for a, b in zip(self.params, other.params))

    def _str_(self):
        return self.name + "(" + ",".join(str(x) for x in self.params) + ")"

    def getNegatedPredicate(self):
        return Predicate(negatePredicate(self.name), self.params)


class Sentence:
    sentence_count = 0

    def _init_(self, string):
        self.sentence_index = Sentence.sentence_count
        Sentence.sentence_count += 1
        self.predicates = []
        self.variable_map = {}
        local = {}

        for predicate in string.split("|"):
            name = predicate[:predicate.find("(")]
            params = []

            for param in predicate[predicate.find("(") + 1: predicate.find(")")].split(","):
                if param[0].islower():
                    if param not in local:  # Variable
                        local[param] = Parameter()
                        self.variable_map[local[param].name] = local[param]
                    new_param = local[param]
                else:
                    new_param = Parameter(param)
                    self.variable_map[param] = new_param

                params.append(new_param)

            self.predicates.append(Predicate(name, params))

    def getPredicates(self):
        return [predicate.name for predicate in self.predicates]

    def findPredicates(self, name):
        return [predicate for predicate in self.predicates if predicate.name == name]

    def removePredicate(self, predicate):
        self.predicates.remove(predicate)
        for key, val in self.variable_map.items():
            if not val:
                self.variable_map.pop(key)

    def containsVariable(self):
        return any(not param.isConstant() for param in self.variable_map.values())

    def _eq_(self, other):
        if len(self.predicates) == 1 and self.predicates[0] == other:
            return True
        return False

    def _str_(self):
        return "".join([str(predicate) for predicate in self.predicates])


class KB:
    def _init_(self, inputSentences):
        self.inputSentences = [x.replace(" ", "") for x in inputSentences]
        self.sentences = []
        self.sentence_map = {}

    def prepareKB(self):
        self.convertSentencesToCNF()
        for sentence_string in self.inputSentences:
            sentence = Sentence(sentence_string)
            for predicate in sentence.getPredicates():
                self.sentence_map[predicate] = self.sentence_map.get(
                    predicate, []) + [sentence]

    def convertSentencesToCNF(self):
        for sentenceIdx in range(len(self.inputSentences)):
            # Do negation of the Premise and add them as literal
            if "=>" in self.inputSentences[sentenceIdx]:
                self.inputSentences[sentenceIdx] = negateAntecedent(
                    self.inputSentences[sentenceIdx])

    def askQueries(self, queryList):
        results = []

        for query in queryList:
            negatedQuery = Sentence(negatePredicate(query.replace(" ", "")))
            negatedPredicate = negatedQuery.predicates[0]
            prev_sentence_map = copy.deepcopy(self.sentence_map)
            self.sentence_map[negatedPredicate.name] = self.sentence_map.get(
                negatedPredicate.name, []) + [negatedQuery]
            self.timeLimit = time.time() + 40

            try:
                result = self.resolve([negatedPredicate], [
                                      False]*(len(self.inputSentences) + 1))
            except:
                result = False

            self.sentence_map = prev_sentence_map

            if result:
                results.append("TRUE")
            else:
                results.append("FALSE")

        return results

    def resolve(self, queryStack, visited, depth=0):
        if time.time() > self.timeLimit:
            raise Exception
        if queryStack:
            query = queryStack.pop(-1)
            negatedQuery = query.getNegatedPredicate()
            queryPredicateName = negatedQuery.name
            if queryPredicateName not in self.sentence_map:
                return False
            else:
                queryPredicate = negatedQuery
                for kb_sentence in self.sentence_map[queryPredicateName]:
                    if not visited[kb_sentence.sentence_index]:
                        for kbPredicate in kb_sentence.findPredicates(queryPredicateName):

                            canUnify, substitution = performUnification(
                                copy.deepcopy(queryPredicate), copy.deepcopy(kbPredicate))

                            if canUnify:
                                newSentence = copy.deepcopy(kb_sentence)
                                newSentence.removePredicate(kbPredicate)
                                newQueryStack = copy.deepcopy(queryStack)

                                if substitution:
                                    for old, new in substitution.items():
                                        if old in newSentence.variable_map:
                                            parameter = newSentence.variable_map[old]
                                            newSentence.variable_map.pop(old)
                                            parameter.unify(
                                                "Variable" if new[0].islower() else "Constant", new)
                                            newSentence.variable_map[new] = parameter

                                    for predicate in newQueryStack:
                                        for index, param in enumerate(predicate.params):
                                            if param.name in substitution:
                                                new = substitution[param.name]
                                                predicate.params[index].unify(
                                                    "Variable" if new[0].islower() else "Constant", new)

                                for predicate in newSentence.predicates:
                                    newQueryStack.append(predicate)

                                new_visited = copy.deepcopy(visited)
                                if kb_sentence.containsVariable() and len(kb_sentence.predicates) > 1:
                                    new_visited[kb_sentence.sentence_index] = True

                                if self.resolve(newQueryStack, new_visited, depth + 1):
                                    return True
                return False
        return True


def performUnification(queryPredicate, kbPredicate):
    substitution = {}
    if queryPredicate == kbPredicate:
        return True, {}
    else:
        for query, kb in zip(queryPredicate.params, kbPredicate.params):
            if query == kb:
                continue
            if kb.isConstant():
                if not query.isConstant():
                    if query.name not in substitution:
                        substitution[query.name] = kb.name
                    elif substitution[query.name] != kb.name:
                        return False, {}
                    query.unify("Constant", kb.name)
                else:
                    return False, {}
            else:
                if not query.isConstant():
                    if kb.name not in substitution:
                        substitution[kb.name] = query.name
                    elif substitution[kb.name] != query.name:
                        return False, {}
                    kb.unify("Variable", query.name)
                else:
                    if kb.name not in substitution:
                        substitution[kb.name] = query.name
                    elif substitution[kb.name] != query.name:
                        return False, {}
    return True, substitution


def negatePredicate(predicate):
    return predicate[1:] if predicate[0] == "" else "" + predicate


def negateAntecedent(sentence):
    antecedent = sentence[:sentence.find("=>")]
    premise = []

    for predicate in antecedent.split("&"):
        premise.append(negatePredicate(predicate))

    premise.append(sentence[sentence.find("=>") + 2:])
    return "|".join(premise)


def getInput(filename):
    with open(filename, "r") as file:
        noOfQueries = int(file.readline().strip())
        inputQueries = [file.readline().strip() for _ in range(noOfQueries)]
        noOfSentences = int(file.readline().strip())
        inputSentences = [file.readline().strip()
                          for _ in range(noOfSentences)]
        return inputQueries, inputSentences


def printOutput(filename, results):
    print(results)
    with open(filename, "w") as file:
        for line in results:
            file.write(line)
            file.write("\n")
    file.close()


if _name_ == '_main_':
    inputQueries_, inputSentences_ = getInput('C:/shushrut/studies/SRM University/SEM 6/AI/7-Unification Resolutiion/Resolution/Input/input_1.txt')
    knowledgeBase = KB(inputSentences_)
    knowledgeBase.prepareKB()
    results_ = knowledgeBase.askQueries(inputQueries_)
    printOutput("output.txt", results_)


##input for resolution
2
Friends(Alice,Bob,Charlie,Diana)
Friends(Diana,Charlie,Bob,Alice)
2
Friends(a,b,c,d)
NotFriends(a,b,c,d)

##implementation of knowledge representation schemes

go :- hypothesize(Animal),
write('I guess that the animal is: '),
write(Animal),
nl,
undo.
hypothesize(cheetah) :- cheetah, !.
hypothesize(tiger) :- tiger, !.
hypothesize(giraffe) :- giraffe, !.
hypothesize(zebra) :- zebra, !.
hypothesize(ostrich) :- ostrich, !.
hypothesize(penguin) :- penguin, !.
hypothesize(albatross) :- albatross, !.
hypothesize(unknown).
cheetah :- mammal,
carnivore,
verify(has_tawny_color),
verify(has_dark_spots).
tiger :- mammal,
carnivore,
verify(has_tawny_color),
verify(has_black_stripes).
giraffe :- ungulate,
verify(has_long_neck),
verify(has_long_legs).
zebra :- ungulate,
verify(has_black_stripes).
ostrich :- bird,
verify(does_not_fly),
verify(has_long_neck).
penguin :- bird,
verify(does_not_fly),
verify(swims),
verify(is_black_and_white).
albatross :- bird,
verify(appears_in_story_Ancient_Mariner),
verify(flys_well).
mammal :- verify(has_hair), !.
mammal :- verify(gives_milk).
bird :- verify(has_feathers), !.
bird :- verify(flys),
verify(lays_eggs).
carnivore :- verify(eats_meat), !.
carnivore :- verify(has_pointed_teeth),
verify(has_claws),
verify(has_forward_eyes).
ungulate :- mammal,
verify(has_hooves), !.
ungulate :- mammal,
verify(chews_cud).
ask(Question) :-
write('Does the animal have the following attribute: '),
write(Question),
write('? '),
read(Response),
nl,
( (Response == yes ; Response == y)
->
assert(yes(Question)) ;
assert(no(Question)), fail).
:- dynamic yes/1,no/1.
verify(S) :-
(yes(S)
->
true ;
(no(S)
->
fail ;
ask(S))).
undo :- retract(yes(_)),fail.
undo :- retract(no(_)),fail.
undo.

##implementation of uncertain methods of application

import matplotlib.pyplot as plt
import seaborn; seaborn.set_style('whitegrid')
import numpy
from pomegranate import *
numpy.random.seed(0)
numpy.set_printoptions(suppress=True)
# The guests initial door selection is
completely random guest =
DiscreteDistribution({'A': 1./3, 'B': 1./3, 'C':
1./3})
# The door the prize is behind is also
completely random prize =
DiscreteDistribution({'A': 1./3, 'B': 1./3, 'C':
1./3})
# Monty is dependent on both the guest
and the prize. monty =
ConditionalProbabilityTable(
[[ 'A', 'A', 'A', 0.0 ],
[ 'A', 'A', 'B', 0.5 ],
[ 'A', 'A', 'C', 0.5 ],
[ 'A', 'B', 'A', 0.0 ],
[ 'A', 'B', 'B', 0.0 ],
[ 'A', 'B', 'C', 1.0 ],
[ 'A', 'C', 'A', 0.0 ],
[ 'A', 'C', 'B', 1.0 ],
[ 'A', 'C', 'C', 0.0 ],
[ 'B', 'A', 'A', 0.0 ],
[ 'B', 'A', 'B', 0.0 ],
[ 'B', 'A', 'C', 1.0 ],
[ 'B', 'B', 'A', 0.5 ],
[ 'B', 'B', 'B', 0.0 ],
[ 'B', 'B', 'C', 0.5 ],
[ 'B', 'C', 'A', 1.0 ],
[ 'B', 'C', 'B', 0.0 ],
[ 'B', 'C', 'C', 0.0 ],
[ 'C', 'A', 'A', 0.0 ],
[ 'C', 'A', 'B', 1.0 ],
[ 'C', 'A', 'C', 0.0 ],
[ 'C', 'B', 'A', 1.0 ],
[ 'C', 'B', 'B', 0.0 ],
[ 'C', 'B', 'C', 0.0 ],
[ 'C', 'C', 'A', 0.5 ],
[ 'C', 'C', 'B', 0.5 ],
[ 'C', 'C', 'C', 0.0 ]], [guest, prize])
# State objects hold both the distribution, and a high
level name. s1 = State(guest, name="guest")
s2 = State(prize, name="prize")
s3 = State(monty, name="monty")
# Create the Bayesian network object with a useful name
model = BayesianNetwork("Monty Hall Problem")
# Add the three states to the network
model.add_states(s1, s2, s3)
# Add edges which represent conditional dependencies, where the
second node is # conditionally dependent on the first node (Monty is
dependent on both guest and prize)
model.add_edge(s1, s3)
model.add_edge(s2, s3)
model.bake()
model.probability([['A', 'B', 'C']])
model.probability([['A', 'B', 'C']])
print(model.predict_proba({}))
print(model.predict_proba([[None, None, None]]))
print(model.predict_proba([['A', None, None]]))
print(model.predict_proba([{'guest': 'A', 'monty': 'B'}]))

##Implementation of blocks world problem

class PREDICATE:
def _str_(self):
pass
def _repr_(self):
pass
def _eq_(self, other) :
pass
def _hash_(self):
pass
def get_action(self, world_state):
pass
#OPERATIONS - Stack, Unstack, Pickup, Putdown
class Operation:
def _str_(self):
pass
def _repr_(self):
pass
def _eq_(self, other) :
pass
def precondition(self):
pass
def delete(self):
pass
def add(self):
pass
class ON(PREDICATE):
def _init_(self, X, Y):
self.X = X
self.Y = Y
def _str_(self):
return "ON({X},{Y})".format(X=self.X,Y=self.Y)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def _hash_(self):
return hash(str(self))
def get_action(self, world_state):
return StackOp(self.X,self.Y)
class ONTABLE(PREDICATE):
def _init_(self, X):
self.X = X
def _str_(self):
return "ONTABLE({X})".format(X=self.X)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def _hash_(self):
return hash(str(self))
def get_action(self, world_state):
return PutdownOp(self.X)
class CLEAR(PREDICATE):
def _init_(self, X):
self.X = X
def _str_(self):
return "CLEAR({X})".format(X=self.X)
self.X = X
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def _hash_(self):
return hash(str(self))
def get_action(self, world_state):
for predicate in world_state:
#If Block is on another block, unstack
if isinstance(predicate,ON) and predicate.Y==self.X:
return UnstackOp(predicate.X, predicate.Y)
return None
class HOLDING(PREDICATE):
def _init_(self, X):
self.X = X
def _str_(self):
return "HOLDING({X})".format(X=self.X)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def _hash_(self):
return hash(str(self))
def get_action(self, world_state):
X = self.X
#If block is on table, pick up
if ONTABLE(X) in world_state:
return PickupOp(X)
#If block is on another block, unstack
else:
for predicate in world_state:
if isinstance(predicate,ON) and predicate.X==X:
return UnstackOp(X,predicate.Y)
class ARMEMPTY(PREDICATE):
def _init_(self):
pass
def _str_(self):
return "ARMEMPTY"
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def _hash_(self):
return hash(str(self))
def get_action(self, world_state=[]):
for predicate in world_state:
if isinstance(predicate,HOLDING):
return PutdownOp(predicate.X)
return None
class StackOp(Operation):
def _init_(self, X, Y):
self.X = X
self.Y = Y
def _str_(self):
return "STACK({X},{Y})".format(X=self.X,Y=self.Y)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def precondition(self):
return [ CLEAR(self.Y) , HOLDING(self.X) ]
def delete(self):
return [ CLEAR(self.Y) , HOLDING(self.X) ]
def add(self):
return [ ARMEMPTY() , ON(self.X,self.Y) ]
class UnstackOp(Operation):
def _init_(self, X, Y):
self.X = X
self.Y = Y
def _str_(self):
return "UNSTACK({X},{Y})".format(X=self.X,Y=self.Y)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def precondition(self):
return [ ARMEMPTY() , ON(self.X,self.Y) , CLEAR(self.X) ]
def delete(self):
return [ ARMEMPTY() , ON(self.X,self.Y) ]
def add(self):
return [ CLEAR(self.Y) , HOLDING(self.X) ]
class PickupOp(Operation):
def _init_(self, X):
self.X = X
def _str_(self):
return "PICKUP({X})".format(X=self.X)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def precondition(self):
return [ CLEAR(self.X) , ONTABLE(self.X) , ARMEMPTY() ]
def delete(self):
return [ ARMEMPTY() , ONTABLE(self.X) ]
def add(self):
return [ HOLDING(self.X) ]
class PutdownOp(Operation):
def _init_(self, X):
self.X = X
def _str_(self):
return "PUTDOWN({X})".format(X=self.X)
def _repr_(self):
return self._str_()
def _eq_(self, other) :
return self._dict_ == other._dict_ and self._class_ == other._class_
def precondition(self):
return [ HOLDING(self.X) ]
def delete(self):
return [ HOLDING(self.X) ]
def add(self):
return [ ARMEMPTY() , ONTABLE(self.X) ]
def isPredicate(obj):
predicates = [ON, ONTABLE, CLEAR, HOLDING, ARMEMPTY]
for predicate in predicates:
if isinstance(obj,predicate):
return True
return False
def isOperation(obj):
operations = [StackOp, UnstackOp, PickupOp, PutdownOp]
for operation in operations:
if isinstance(obj,operation):
return True
return False
def arm_status(world_state):
for predicate in world_state:
if isinstance(predicate, HOLDING):
return predicate
return ARMEMPTY()
class GoalStackPlanner:
def _init_(self, initial_state, goal_state):
self.initial_state = initial_state
self.goal_state = goal_state
def get_steps(self):
#Store Steps
steps = []
#Program Stack
stack = []
#World State/Knowledge Base
world_state = self.initial_state.copy()
#Initially push the goal_state as compound goal onto the stack
stack.append(self.goal_state.copy())
#Repeat until the stack is empty
while len(stack)!=0:
#Get the top of the stack
stack_top = stack[-1]
#If Stack Top is Compound Goal, push its unsatisfied goals onto stack if
type(stack_top) is list:
compound_goal = stack.pop()
for goal in compound_goal:
if goal not in world_state:
stack.append(goal)
#If Stack Top is an action
elif isOperation(stack_top):
#Peek the operation
operation = stack[-1]
all_preconditions_satisfied = True
#Check if any precondition is unsatisfied and push it onto program stack
for predicate in operation.delete():
if predicate not in world_state:
all_preconditions_satisfied = False
stack.append(predicate)
#If all preconditions are satisfied, pop operation from stack and execute it if
all_preconditions_satisfied:
stack.pop()
steps.append(operation)
for predicate in operation.delete():
world_state.remove(predicate)
for predicate in operation.add():
world_state.append(predicate)
#If Stack Top is a single satisfied goal
elif stack_top in world_state:
stack.pop()
#If Stack Top is a single unsatisfied goal
else:
unsatisfied_goal = stack.pop()
#Replace Unsatisfied Goal with an action that can complete it
action = unsatisfied_goal.get_action(world_state)
stack.append(action)
#Push Precondition on the stack
for predicate in action.precondition():
if predicate not in world_state:
stack.append(predicate)
return steps
if _name_ == '_main_':
initial_state = [
ON('B','A'),
ON('C','B'),
ONTABLE('A'),ONTABLE('D'),
CLEAR('C'),CLEAR('D'),
ARMEMPTY()
]
goal_state = [
ON('B','D'),ON('C','A'),
ONTABLE('D'),ONTABLE('A'),
CLEAR('B'),CLEAR('C'),
ARMEMPTY()
]
goal_stack = GoalStackPlanner(initial_state=initial_state, goal_state=goal_state)
steps = goal_stack.get_steps()
print(steps)

##Implementation of learning alogitrm for an application

a)import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
%matplotlib inline
dataset=pd.read_csv('student_scores.csv')
dataset.head()
dataset.shape
dataset.describe()
dataset.plot(x='Hours', y='scores', style='o')
plt.title('Hours vs Percentage')
plt.xlabel('Hours Studied')
plt.ylabel('Percentage Score')
plt.show()
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 1].values
X_train, X_test, y_train, y_test = train_test_split(X,
y,test_size=0.2, random_state=0)
print('X train shape: ', X_train.shape)
print('Y train shape: ', y_train.shape)
print('X test shape: ', X_test.shape)
print('Y test shape: ', y_test.shape)
regressor = LinearRegression()
regressor.fit(X_train, y_train)
print(regressor.intercept_)
print(regressor.coef_)
y_pred = regressor.predict(X_test)
df = pd.DataFrame({'Actual': y_test,
'Predicted': y_pred}) print(df)
print('Mean Absolute Error:',
metrics.mean_absolute_error (y_test, y_pred))
print('Mean Squared Error:',
metrics.mean_squared_error (y_test, y_pred))
print('Root Mean Squared Error:',
np.sqrt(metrics.mean_squared_error (y_test, y_pred)))
b)import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
dataset = pd.read_csv('diabetes.csv')
print(dataset.head())
dataset = pd.read_csv('diabetes.csv')
print(dataset.head())
dataset.head()
def diagnosis(x):
if x=='M' :
return 1
if x=='B' :
return 0
dataset['DiabetesPedigreeFunction'] =
dataset['DiabetesPedigreeFunction'].apply(diagnosis)
print(dataset)
svc_classifier=SVC(kernel='rbf')
svc_classifier
Y = dataset['DiabetesPedigreeFunction']
X = dataset.drop(columns=['DiabetesPedigreeFunction'])
X_train, X_test, Y_train, Y_test =
train_test_split(X, Y, test_size=0.2,
random_state=9)
X_train, X_test, Y_train, Y_test =
train_test_split(X, Y, test_size=0.2,
random_state=9)
print('X train shape: ', X_train.shape)
print('Y train shape: ', Y_train.shape)
print('X test shape: ', X_test.shape)
print('Y test shape: ', Y_test.shape)
svc_classifier= SVC(kernel='poly')
c) import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
%matplotlib inline
data=pd.read_csv('mall_customers.csv')
print(data.head())
inVsout=data.iloc[:,[3,4]]
inVsout
plt.scatter(inVsout.iloc[:0],inVsout.iloc[:,1])
kmeans=KMeans(n_clusters=5)
kmeans.fit(inVsout)
plt.scatter(inVsout.iloc[:0],inVsout.iloc[:,1],c=kmeans.la
bels_,cmap='rain bow')
plt.show()

##development of ensemble model for an application

Bagged decision tree:
import pandas as pd
import numpy as np
from sklearn import model_selection
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
url = "diabetes.csv"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass',
'pedi', 'age','class']
dataframe = pd.read_csv(url, names=names)
dataframe = dataframe.iloc[1:]
array = dataframe.values
X = array[:,0:8]
Y = array[:,8]
seed = 7
kfold = model_selection.KFold(n_splits=10,
random_state=seed, shuffle=True)
cart = DecisionTreeClassifier()
num_trees = 100
dataframe = dataframe.replace(r'^\s*$', np.nan, regex=True) model =
BaggingClassifier(base_estimator=cart,
n_estimators=num_trees, random_state=seed)
results = model_selection.cross_val_score(model, X, Y,
cv=kfold, error_score='raise')
print(results)
print(results.mean())
Random Forest:
import pandas
from sklearn import model_selection
from sklearn.ensemble import
RandomForestClassifier url = "diabetes.csv"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass',
'pedi', 'age','class']
dataframe = pandas.read_csv(url, names=names)
dataframe = dataframe.iloc[1:]
array = dataframe.values
X = array[:,0:8]
Y = array[:,8]
seed = 7
num_trees = 100
max_features = 3
kfold = model_selection.KFold(n_splits=10)
model =
RandomForestClassifier(n_estimators=num_trees, max_feat
ures=max_features)
results = model_selection.cross_val_score(model, X, Y, cv=kfold)
print(results)
print(results.mean())
Extra Trees:
import pandas
from sklearn import model_selection
from sklearn.ensemble import
RandomForestClassifier from sklearn.ensemble import
ExtraTreesClassifier
url = "diabetes.csv"
names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass',
'pedi', 'age','class']
dataframe = pandas.read_csv(url, names=names)
dataframe = dataframe.iloc[1:]
array = dataframe.values
X = array[:,0:8]
Y = array[:,8]
seed = 7
num_trees = 100
max_features = 7
kfold = model_selection.KFold(n_splits=10)
model = ExtraTreesClassifier(n_estimators=num_trees,
max_features=max_features)
results = model_selection.cross_val_score(model, X, Y,
cv=kfold) print(results)
print(results.mean())

##Implementation of NLP Programs

from nltk.tokenize import sent_tokenize, word_tokenize
example_string = """
... Muad'Dib learned rapidly because his first training was
in how to learn.
... And the first lesson of all was the basic trust that he
could learn. ... It's shocking to find how many people do not
believe they can learn, ... and how many more believe learning
to be difficult.""" sent_tokenize(example_string)
word_tokenize(example_string)
Filtering stop words:
nltk.download("stopwords")
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
worf_quote = "Sir, I protest. I am not a merry man!"
words_in_quote = word_tokenize(worf_quote)
words_in_quote
stop_words = set(stopwords.words("english"))
filtered_list = []
for word in words_in_quote:
if word.casefold() not in stop_words:
filtered_list.append(word)
filtered_list = [
word for word in words_in_quote if word.casefold() not in
stop_words ]
filtered_list
Stemming:
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
stemmer = PorterStemmer()
string_for_stemming = """
The crew of the USS Discovery discovered many
discoveries. Discovering is what explorers
do."""
words = word_tokenize(string_for_stemming)
words
stemmed_words = [stemmer.stem(word) for word in words]
stemmed_words
Tagged parts of speech:
from nltk.tokenize import word_tokenize
sagan_quote = """
If you wish to make an apple pie from scratch,
you must first invent the universe."""
words_in_sagan_quote = word_tokenize(sagan_quote)
import nltk
nltk.pos_tag(words_in_sagan_quote)
jabberwocky_excerpt = """
... 'Twas brillig, and the slithy toves did gyre and gimble in
the wabe: ... all mimsy were the borogoves, and the mome raths
outgrabe.""" words_in_excerpt =
word_tokenize(jabberwocky_excerpt)
nltk.pos_tag(words_in_excerpt)
Lemmatizing:
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize("scarves")
string_for_lemmatizing = "The friends of DeSoto love scarves."
words = word_tokenize(string_for_lemmatizing)
words
lemmatized_words = [lemmatizer.lemmatize(word) for word
in words] lemmatized_words
lemmatizer.lemmatize("worst")
lemmatizer.lemmatize("worst", pos="a")
Chunking:
from nltk.tokenize import word_tokenize
lotr_quote = "It's a dangerous business, Frodo, going out
your door." words_in_lotr_quote =
word_tokenize(lotr_quote)
words_in_lotr_quote
nltk.download("averaged_perceptron_tagger")
lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)
lotr_pos_tags
grammar = "NP: {<DT>?<JJ>*<NN>}"
chunk_parser = nltk.RegexpParser(grammar)
tree = chunk_parser.parse(lotr_pos_tags)


## Apply deep learning methods to solve an application

!pip install tensorflow
!pip install numpy
!pip install keras
!pip install pillow
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from keras.utils import np_utils
(x_train, y_train), (x_test, y_test) =
mnist.load_data() print(x_train.shape,
y_train.shape)
model = Sequential()
model.add(Conv2D(32, kernel_size=(3,
3),activation='relu',input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
y_train = keras.utils.np_utils.to_categorical(y_train,
num_classes) y_test =
keras.utils.np_utils.to_categorical(y_test, num_classes)
#Normalize the data
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')
batch_size = 128
epochs = 10
from tensorflow import keras
model.compile(loss=keras.losses.categorical_crossentropy,o
ptimizer =
keras.optimizers.Adadelta(),metrics=['accuracy'])
hist =
model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,ve
rbose=1,va lidation_data=(x_test, y_test))
print("The model has successfully trained")
score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:;', score[0])
print('Test accuracy:', score[1])

# Python3 program to solve N Queen
# Problem using backtracking
global N
N = 4
 
def printSolution(board):
    for i in range(N):
        for j in range(N):
            print (board[i][j], end = " ")
        print()
 
# A utility function to check if a queen can
# be placed on board[row][col]. Note that this
# function is called when "col" queens are
# already placed in columns from 0 to col -1.
# So we need to check only left side for
# attacking queens
def isSafe(board, row, col):
 
    # Check this row on left side
    for i in range(col):
        if board[row][i] == 1:
            return False
 
    # Check upper diagonal on left side
    for i, j in zip(range(row, -1, -1),
                    range(col, -1, -1)):
        if board[i][j] == 1:
            return False
 
    # Check lower diagonal on left side
    for i, j in zip(range(row, N, 1),
                    range(col, -1, -1)):
        if board[i][j] == 1:
            return False
 
    return True
 
def solveNQUtil(board, col):
     
    # base case: If all queens are placed
    # then return true
    if col >= N:
        return True
 
    # Consider this column and try placing
    # this queen in all rows one by one
    for i in range(N):
 
        if isSafe(board, i, col):
             
            # Place this queen in board[i][col]
            board[i][col] = 1
 
            # recur to place rest of the queens
            if solveNQUtil(board, col + 1) == True:
                return True
 
            # If placing queen in board[i][col
            # doesn't lead to a solution, then
            # queen from board[i][col]
            board[i][col] = 0
 
    # if the queen can not be placed in any row in
    # this column col then return false
    return False
 
# This function solves the N Queen problem using
# Backtracking. It mainly uses solveNQUtil() to
# solve the problem. It returns false if queens
# cannot be placed, otherwise return true and
# placement of queens in the form of 1s.
# note that there may be more than one
# solutions, this function prints one of the
# feasible solutions.
def solveNQ():
    board = [ [0, 0, 0, 0],
              [0, 0, 0, 0],
              [0, 0, 0, 0],
              [0, 0, 0, 0] ]
 
    if solveNQUtil(board, 0) == False:
        print ("Solution does not exist")
        return False
 
    printSolution(board)
    return True
 
# Driver Code
solveNQ()